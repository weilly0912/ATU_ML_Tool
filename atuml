#!/usr/bin/env python3

import os
import re
import sys
import cv2
import csv
import time
import socket
import psutil
import pathlib
import requests
import numpy as np
import tflite_runtime.interpreter as tflite
import subprocess

from random import randint
from argparse import ArgumentParser

def args_parser():
    parser = ArgumentParser()
    parser.add_argument('--info', default=None, help="Provide information.")
    parser.add_argument('--run', default=None, help="Run a model.\n Example: atuml --run <model.tflite> -a [NPU/CPU]")
    parser.add_argument('-bv', '--bsp_version', default=None, help="Specify BSP version.\n Example: atuml -bv 1")
    parser.add_argument('-c', '--vela_compiler_tool', default=None, help="Use Vela compiler tool.\n Example: atuml --vela_compiler_tool . --recompile 1")
    parser.add_argument('-rc', '--recompile', default=0, help="Recompile the model.")
    parser.add_argument('-b', '--benchmark', default=None, help="Run benchmark.\n Example: atuml -b <model.tflite> -a [NPU/CPU]")
    parser.add_argument('-acc', '--accelerator', default="NPU", help="Specify the accelerator.")
    parser.add_argument("--csv", default="result.csv", help="Specify the CSV file.\n Example: --csv [*.csv]")
    parser.add_argument("--csv_status", default="a", help="Specify the CSV status.\n Example: --csv_status [ a / w / w+ ]")
    parser.add_argument("--delegate", default="vx", help="Specify the delegate.\n Example: --delegate [ vx / ethosu / xnnpack ]") 
    parser.add_argument('--benchmark_loop_generate_file', default=None, help="Generate benchmark loop file.\nExample: atuml --benchmark_loop_generate_file ATU_Model_Zoo/Classification/\n--csv_status 'w+' --delegate 'vx'")
    parser.add_argument('--demo', default=None, help="DEMO appliction.\n Example: atuml --demo help")
    parser.add_argument('--cam', '--camera', default=0, nargs='+', help="DEMO appliction.\n Example: atuml --demo ObjectDetect_MobileNetSSD --cam 1 2 [Eanble / Camera Device]")
    parser.add_argument('--refer', default=0, help="Reference")
    return parser.parse_args()

def check_internet_connection():
    try:
        response = requests.get("http://www.google.com", timeout=5)
        return 1
    except requests.ConnectionError:
        print("Not connected to the internet")
        return 0

def get_csv_lastmodel( csv_file ): #
    with open(csv_file, 'r', newline='') as csvfile: 
        reader = csv.reader(csvfile)
        last_model = None
        for row in reader :
            last_model = row[1]
    return last_model

def show_Message(filename):
    print("-------------------------------")
    print(filename)
    print("-------------------------------")

def InferenceDelegate( model, delegate ):
    if (delegate=="vx") :
        interpreter = tflite.Interpreter(model, experimental_delegates=[ tflite.load_delegate("/usr/lib/libvx_delegate.so") ])
    elif(delegate=="ethosu"):
        interpreter = tflite.Interpreter(model, experimental_delegates=[tflite.load_delegate("/usr/lib/libethosu_delegate.so")])
    elif(delegate=="xnnpack"):
        interpreter = tflite.Interpreter(model)
    else :
        interpreter = tflite.Interpreter(model)
    return interpreter

def DelegateEngine(model, accelerator):
    if accelerator == 'NPU'  or accelerator == "npu":
        os.environ["USE_GPU_INFERENCE"] = "0"
        if model[-11:] == 'vela.tflite' : 
            delegate = "ethosu"
        else :
            delegate = "vx"
    elif accelerator == 'GPU'  or accelerator == "gpu":
        os.environ["USE_GPU_INFERENCE"] = "1"
        if model[-11:] == 'vela.tflite' : 
            delegate = "ethosu"
        else :
            delegate = "vx"
    elif accelerator == "CPU" or accelerator == "cpu":
        delegate = "xnnpack"
    else:
        delegate = "None"
    return delegate

def AcceleratorEngine(machine):
    if machine=="imx8mpevk" or \
       machine=="imx8mp-lpddr4-ndm" or \
       machine=="imx8mpul-lpddr4-evk" or \
       machine=="opkiller" or \
       machine=="imx93evk" or \
       machine=="opgyro"  :
       return "npu"
    elif machine=="imx8qmmek" or \
         machine=="imx8qmddr4arm2" or \
         machine=="imx8qmlpddr4arm2" or \
         machine=="imx8qxp-b0-mek" or \
         machine=="imx8qxpc0lpddr4arm2" or \
         machine=="imx8qxpc0mek" or \
         machine=="imx8qxplpddr4arm2" or \
         machine=="imx8qxpmek" :
       return "gpu"
    else :
       return "cpu"
       # gpu


class ATUML:
    def __init__(self):
        self.args = args_parser()
        self.atuml_set = {"1","2","3"}
        self.atuml_src_format = {"onnx","ckpt","pb","pytorch"}
        self.hostname = socket.gethostname()
        self.acceleratorEngine = AcceleratorEngine(self.hostname)

    def bsp_version(self):
        command_ouput = subprocess.check_output('uname -a', shell=True)
        pattern = r"\d+\.\d+\.\d+"
        match = re.search(pattern, command_ouput.decode())
        if match:
            version = match.group()
        else:
            version = " "
        return version

    def atuml_info(self):
        print("------------------------------------------- FW INFO  -------------------------------------------")

        # PCIe
        PCIe_Status = os.popen("lspci").read()
        if PCIe_Status:
            print("--------------------------------------------  PCIe  --------------------------------------------")
            print(PCIe_Status)
            print("\n\n")

        # Camera
        Camera_Status = os.popen("v4l2-ctl --list-devices").read()
        if Camera_Status:
            print("-------------------------------------------- CAMERA --------------------------------------------")
            print(Camera_Status)
            print("Please input command If you want check format : v4l2-ctl -d /dev/video0 --list-formats-ext")
            print("\n\n")

        CameraFormat_Status = os.popen("v4l2-ctl -d /dev/video0 --list-formats-ext").read()
        if CameraFormat_Status:
            print("-------------------------------------- CAMERA  Format ------------------------------------------")
            print(CameraFormat_Status)
            print("\n\n")
      
        # USB
        USB_Status = os.popen("lsusb").read()
        if USB_Status:
            print("--------------------------------------------  USB   --------------------------------------------")
            print(USB_Status)
            print("\n\n")

        # I2C
        I2C_0_Status = os.popen("i2cdetect -y 0").read()
        I2C_1_Status = os.popen("i2cdetect -y 1").read()
        I2C_2_Status = os.popen("i2cdetect -y 2").read()
        I2C_3_Status = os.popen("i2cdetect -y 3").read()
        if 0:
            print("--------------------------------------------  I2C   --------------------------------------------")
            print("Channel 0\n");print(I2C_0_Status);print("\n")
            print("Channel 1\n");print(I2C_1_Status);print("\n")
            print("Channel 2\n");print(I2C_2_Status);print("\n")
            print("Channel 3\n");print(I2C_3_Status);print("\n")
            print("\n\n")

        # ETH
        ETH_Status = os.popen("ifconfig").read()
        if ETH_Status:
            print("--------------------------------------------  ETH   --------------------------------------------")
            eth0_inet = re.search('eth0.*?inet (\d+\.\d+\.\d+\.\d+)', ETH_Status, re.DOTALL)
            rx_inet = re.search('eth0.*?RX.*?bytes (\d+) \((.*?)\)', ETH_Status, re.DOTALL)
            tx_inet = re.search('eth0.*?TX.*?bytes (\d+) \((.*?)\)', ETH_Status, re.DOTALL)
            if(eth0_inet):print("eth0 (IP) :",eth0_inet.group(1),  "  RX:", rx_inet.group(2),  "  TX:", tx_inet.group(2))
            
            eth1_inet = re.search('eth1.*?inet (\d+\.\d+\.\d+\.\d+)', ETH_Status, re.DOTALL)
            rx_inet = re.search('eth1.*?RX.*?bytes (\d+) \((.*?)\)', ETH_Status, re.DOTALL)
            tx_inet = re.search('eth1.*?TX.*?bytes (\d+) \((.*?)\)', ETH_Status, re.DOTALL)
            if(eth1_inet):print("eth1 (IP) :",eth1_inet.group(1),  "  RX:", rx_inet.group(2),  "  TX:", tx_inet.group(2))
            print("\n\n")

    def atuml_reference(self):
        print("\n")
        print("--------------------------------------------------------------------------------");
        print("Reference Info")
        print("--------------------------------------------------------------------------------");print("\n")
        print("ATU Model Zoo : \n  https://github.com/weilly0912/ATU_Model_Zoo");print("\n")
        print("ATU AI Demo : \n  https://github.com/weilly0912/ATU_NXP_AI_DEMO");print("\n")
        print("ATU-Book Document : \n  https://www.wpgdadatong.com/blog/detail/74338");print("\n")
        print("ATU Model Converter : \n")
        print(" (1) 【Tools - Converter】Tensorflow to Tensorflow Lite Conveter.ipynb  :  \n    https://colab.research.google.com/drive/1IImEYkTguXbsso8uVsfUqLJqDZqMM8cv?usp=sharing")
        print(" (2) 【Tools - Converter】Tensorflow JS to Tensorflow Lite.ipynb :  \n    https://colab.research.google.com/drive/1T5a997NZj28L_Avyjlfh9WG98cxID0cr?usp=sharing")
        print(" (3) 【Tools - Converter】Pytorch to Tensorflow Lite Conveter.ipynb  :  \n    https://colab.research.google.com/drive/1K0l5YVpBIgMz4SNa0TcSz0XJNMbcwIWf?usp=sharing")
        print(" (4) 【Tools - Converter】ONNX Model Zoo Converter.ipynb  :  \n    https://colab.research.google.com/drive/1VPU9IMdRNcpd9rn2b8Ves1u_36inELnP?usp=sharing")
        print(" (5) 【Tools - Converter】ONNX Model Zoo to Tensorflow Lite Conveter.ipynb :  \n    https://colab.research.google.com/drive/1Xvkw5dHm_UQXaBYSvVQlZ-_S1kN3lvKF?usp=sharing");print("\n")
        print("AI training  : \n")
        print(" (1) Colab -> 【Roboflow】 Drowsiness (DMS) detection.ipynb  :  \n    https://colab.research.google.com/drive/15SeO3VUxtTb0TiODkkvZBSwyeFCP6Ac0?usp=sharing")
        print(" (2) Colab -> 【Application】ObjectDetection_MobilNet SSD.ipynb  :  \n    https://colab.research.google.com/drive/1ICjvo8IVEt2DZEsM-vyII_Ry8ntML9zA?usp=sharing")
        print(" (3) NXP eIQ® Toolkit for End-to-End Model Development and Deployment  \n    https://www.nxp.com/design/design-center/software/eiq-ml-development-environment/eiq-toolkit-for-end-to-end-model-development-and-deployment:EIQ-TOOLKIT")
        print("    【ATU Book-i.MX8系列 - eIQ Toolkit】eIQ Portal 快速使用介紹  \n  https://www.wpgdadatong.com/blog/detail/45389");print("\n")
        print("i.MX Machine Learning User's Guide : \n  https://www.nxp.com/docs/en/user-guide/IMX-MACHINE-LEARNING-UG.pdf");print("\n")
        print("i.MX Linux User's Guide : \n  https://www.nxp.com/docs/en/user-guide/IMX_LINUX_USERS_GUIDE.pdf");print("\n")
        print("Embedded Linux for i.MX Applications Processors : \n  https://www.nxp.com/design/design-center/software/embedded-software/i-mx-software/embedded-linux-for-i-mx-applications-processors:IMXLINUX");print("\n")
        print("eIQ® ML Software Development Environment : \n https://www.nxp.com/design/design-center/software/eiq-ml-development-environment:EIQ");print("\n")
        
    def run(self, model, accelerator, visionable):
        # select accelerator
        delegate = DelegateEngine(model,accelerator)
        if model[-6:] == "tflite":
            # initial
            interpreter = InferenceDelegate(model,delegate)
            input_details  = interpreter.get_input_details()#input_mem = input_details[0]['shape'].prod() * np.dtype(input_details[0]['dtype']).itemsize
            output_details = interpreter.get_output_details()#output_mem = output_details[0]['shape'].prod() * np.dtype(output_details[0]['dtype']).itemsize
            try:
                interpreter.allocate_tensors()
            except Exception as e:
                print("Error Message : allocate_tensors Fail")
                return -1

            # data nChannel
            nChannel = len(input_details[0]['shape'])
            if (nChannel==1):
                input_data_array =np.zeros(input_details[0]['shape'][0])      
            elif (nChannel==2):
                input_data_array =np.zeros((input_details[0]['shape'][0],input_details[0]['shape'][1]))
            elif (nChannel==3):
                input_data_array =np.zeros((input_details[0]['shape'][0],input_details[0]['shape'][1],input_details[0]['shape'][2]))
            elif (nChannel==4):
                input_data_array =np.zeros((input_details[0]['shape'][0],input_details[0]['shape'][1],input_details[0]['shape'][2],input_details[0]['shape'][3]))
            else:
                return 1

            # data type
            if input_details[0]['dtype']==np.float32 :
                interpreter.set_tensor(input_details[0]['index'], input_data_array.astype("float32") )
            elif input_details[0]['dtype']==np.int8 :
                interpreter.set_tensor(input_details[0]['index'], input_data_array.astype("int8") )
            else :
                interpreter.set_tensor(input_details[0]['index'], input_data_array.astype("uint8") )

            # warm-up
            interpreter.invoke()

            if(visionable==True and accelerator == "NPU" and delegate!="ethosu"):
                print("--------------------------------------------   CLK --------------------------------------------")
                print("                      clock           count     count  count  rate    accuracy      phase     cycle    enable")
                print(subprocess.check_output("cat /sys/kernel/debug/clk/clk_summary | grep -i npu", shell=True).decode("utf-8"))

            # interpreter
            interpreter_time_start = time.time()
            interpreter.invoke()
            interpreter_time_end   = time.time()
            interpreter_spend_time = (interpreter_time_end - interpreter_time_start)*1000
            if(visionable): 
                print("--------------------------------------------  INFO --------------------------------------------")
                print( " Inference Time ("  + accelerator + ")= ",  interpreter_spend_time, " ms" )
                print( " Model Size = ",  os.popen("du -h " + model).read().split()[0][:-1], " MB" )
            
        else :
            interpreter_time_end = 0
            if(visionable):  print("Please use tensorflow lite model format !")

        return interpreter_spend_time
    
    def vela_compiler_tool(self, target, recompile):
        path = target
        if self.hostname=="opgyro" or self.hostname=="imx93evk": 
            if os.path.isdir(path):
                for dirPath, dirNames, fileNames in os.walk(path):
                    for file in fileNames:
                        filename, extension = os.path.splitext(file)
                        IF_Compiled = False
                        
                        # re-setting compile
                        if(recompile=='1'):
                            IF_Compiled = False
                        else :
                            # compare
                            for tmp in fileNames:
                                if tmp== (filename + "_vela.tflite") :
                                    IF_Compiled = True
                                    print("The " + filename + " has comipled!!")

                        # compile vela
                        if extension == ".tflite" and  IF_Compiled== False :
                            if filename[-4:] != "vela" and (filename[-5:] == "quant" or filename[-4:] == "int8") : # ignore vela model
                                # gerenate vela model
                                cmd  = 'vela {} --output-dir .'.format(file);print(cmd)
                                os.chdir(dirPath)#os.chdir(os.getcwd() + dirPath[1:])
                                try :
                                    output = subprocess.check_output(cmd, shell=True)
                                    os.system('rm *.csv')
                                except :
                                    pass

                                # save result
                                os.system('mkdir -p vela-detail')
                                with open( "vela-detail/" + file + ".txt", "w") as file:
                                    file.write(output.decode("utf-8")) 
        else :
            print("this is function used imx93 chip")

    def benchmark(self, model, accelerator):
        # Select Accelerator
        if accelerator == 'NPU' or accelerator == "npu":
             if model[-11:] == 'vela.tflite' : 
                command_accelerator = "--external_delegate_path=/usr/lib/libethosu_delegate.so"
             else :
                command_accelerator = "--external_delegate_path=/usr/lib/libvx_delegate.so"
        elif accelerator == "CPU" or accelerator == "cpu":
            command_accelerator = "--use_xnnpack=true"
        else:
            command_accelerator = "--use_xnnpack=false"   

        # Find Tensorflow folder
        path = '/usr/bin/'
        for folder in os.listdir(path):
            if folder.startswith('tensorflow'):
                tf_folder_path = os.path.join(path, folder)
        
        #Benckmend binary
        command_binary = tf_folder_path + "/examples/benchmark_model"
        
        #Running
        command_benchmark = command_binary + " " + command_accelerator+ " --graph={}".format(model)
        if accelerator == 'NPU' or accelerator == "npu":
            if model[-10:] == 'vela.tflite' : 
                print("------------------------------------------------ \n ARM ethous NPU - Benchmark "  +"\n ------------------------------------------------ \n", command_benchmark)
            # For IMX 8M PLUS 
            elif model[-6:] == 'tflite': 
                print("------------------------------------------------ \n NPU - Benchmark "  +" \n ------------------------------------------------ \n", command_benchmark)
        elif accelerator == 'cpu' or accelerator == "cpu":
            print("------------------------------------------------ \n CPU  - Benchmark " +"\n ------------------------------------------------ \n", command_benchmark)
        else :
            print("Please use tflite format and NPU/CPU.")
            print("example : atuml -b *.tflite -a [NPU/CPU] ")
        #self.atuml_set[target]().run()

        # info crash
        output = os.popen(command_benchmark).read()
        model_size   = re.search("The input model file size \(MB\): (\d+\.\d+)", output).group(1)
        session_time = re.search("Initialized session in (\d+\.\d+)ms", output).group(1)
        inference_pattern_init = re.search("Inference timings in us: Init: (\d+)", output).group(1)
        inference_pattern_first = re.search("First inference: (\d+)", output).group(1)
        inference_pattern_warmup= re.search("Warmup \(avg\): ([\d,]+\.\d+)", output).group(1)
        inference_pattern= re.search("Inference \(avg\): ([\d,]+\.\d+)", output).group(1)

        print("----------------------------------------------------------------------------")
        print(output)
        print("Model size:", model_size, "MB")
        print("Session initialization time:", session_time, "us")
        print("Init time:", inference_pattern_init, " us")
        print("First inference time:",  inference_pattern_first, " us")
        print("Warmup (avg):",  inference_pattern_warmup, " us")
        print("Inference (avg):",  inference_pattern, " us")
        
    def benchmark_loop_generate_file(self, Folder, CSV_File, CSV_Status, Delegate):
        # get bsp version
        BV = self.bsp_version()
        # check file exist
        if not os.path.isfile(CSV_File):
            with open(CSV_File, "w") as f:
                print(f"File '{CSV_File}' created.")
        else:
            print(f"File '{CSV_File}' already exists.")

        # check file status
        lastmodel = get_csv_lastmodel (CSV_File)
        if CSV_Status == "a" :
            csv_status_keep = 1
        else :
            csv_status_keep = 0

        # recoder
        with open(CSV_File, CSV_Status, newline='') as csvfile: #'w'
            writer = csv.writer(csvfile)
            if CSV_Status != "a" :
                writer.writerow(['class', 'filename', 'inference','cpu','rss', 'cache', 'size']) # cache(MB) ,Size(MB)

            for folder, subfolders, filenames in os.walk(Folder):
                for filename in filenames:
                    if( (Delegate =="vx" and filename[-7:]=='.tflite' ) or
                        (Delegate =="ethosu" and filename[-11:]=='vela.tflite') ): 
                        if (csv_status_keep==0) :
                            show_Message(filename)
                            model_path  =  f'{folder}/{filename}'
                            model_path = model_path.replace("//", "/")
                            os.system("sync; echo 3 > /proc/sys/vm/drop_caches")
                            try :
                                # interfence
                                #interpreter_spend_time = self.run(model_path, "NPU", False)
                                print("atuml --run " + model_path)
                                run_text = os.popen("atuml --run " + model_path).read()
                                inference_time_match = re.search('Inference Time \(NPU\)=\s+(\d+\.\d+)', run_text)
                                try :
                                    interpreter_spend_time = inference_time_match.group(1)
                                    class_ = folder.split("/")[-2]
                                    name_ = model_path.split("/")[-1]
                                    size_ = os.stat(model_path).st_size 
                                    writer.writerow( [ class_, name_, str(round(float(interpreter_spend_time),2)), str(psutil.cpu_percent(interval=5)),  str(round(float(psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024 / 1024),2)),  str(round(float(psutil.virtual_memory().cached / 1024 / 1024) ,2)), str(round(float(size_/(1024*1024)),2)) ])
                                except :
                                    name_ = model_path.split("/")[-1]
                                    size_ = os.stat(model_path).st_size 
                                    writer.writerow( [ class_, name_, "fail", "fail",  "fail", str(round(float(size_/(1024*1024)),2))  ])
                            except :
                                print(model_path + "is fail")

                        else :
                            name_ = folder.split("/")[-1]
                            if lastmodel == name_ : csv_status_keep = 0

    def demo(self, application):
        app_run = False
        app_gst = False
        if application == "ObjectDetect_YOLOv5s" :
            application_name = "YOLOv5s_ObjectDetect"
            test_image_name = "zidane.jpg"
            model_name = "yolov5s-nxp_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "ObjectDetect_YOLOv5n" :
            application_name = "YOLOv5n_ObjectDetect"
            test_image_name = "zidane.jpg"
            model_name = "yolov5n_256x256_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "Segmentation_YOLOv5s" :
            application_name = "YOLOv5s_ObjectSegmation"
            test_image_name = "zidane.jpg"
            model_name = "yolov5s-seg_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "ObjectDetect_MobileNetSSD" :
            application_name = "MobileNetSSD_ObjectDetector"
            test_image_name = "dog.bmp"
            model_name = "mobilnet_ssd_v1_quant.tflite"
            label_name = "coco_labels.txt"
            app_run = True
        elif application == "ObjectDetect_YOLOv8n" :
            application_name = "YOLOv8n_ObjectDetect"
            test_image_name = "zidane.jpg"
            model_name = "yolov8n_integer_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "Segmentation_YOLOv8s" :
            application_name = "YOLOv8s_ObjectSegmataion"
            test_image_name = "showgril_car.jpg"
            model_name = "yolov8s-seg_integer_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "PoseEstimation_YOLOv8s" :
            application_name = "YOLOv8s_PoseEstimation"
            test_image_name = "bus.jpg"
            model_name = "yolov8s-pose_integer_quant.tflite"
            label_name = ""
            app_run = True
        elif application == "ObjectDetect_Gstreamer" : #共用
            application_name = "MobileNetSSD_ObjectDetector"
            test_image_name = "dog.bmp"
            model_name = "mobilnet_ssd_v1_quant.tflite"
            label_name = "coco_labels.txt"
            app_run = True
            app_gst = True

        if application == "help":
            print("Example :")
            print("   atuml --demo ObjectDetect_MobileNetSSD")
            print("   atuml --demo ObjectDetect_YOLOv5s")
            print("   atuml --demo ObjectDetect_YOLOv5n")
            print("   atuml --demo ObjectDetect_YOLOv8n")
            print("   atuml --demo Segmentation_YOLOv5s")
            print("   atuml --demo Segmentation_YOLOv8s")
            print("   atuml --demo PoseEstimation_YOLOv8s")
            print("   atuml --demo ObjectDetect_Gstreamer")
            print("Or, Open Camera : atuml --demo ObjectDetect_MobileNetSSD --cam 1 2" )

        # Start
        if (app_run):
            # Download Model
            if not os.path.exists("/home/root/.ATU_NXP_AI_DEMO/" + application_name) :
                if (check_internet_connection()):
                    os.system("mkdir -p /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model")
                    os.system("mkdir -p /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/img")
                    os.system("mkdir -p /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/label")
                    os.system("mkdir -p /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/output")
                    os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/app.py -L https://raw.githubusercontent.com/weilly0912/ATU_NXP_AI_DEMO/v12.0/TensorflowLite_DEMO/" + application_name +"/app.py")
                    os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/plots.py -L https://raw.githubusercontent.com/weilly0912/ATU_NXP_AI_DEMO/v12.0/TensorflowLite_DEMO/" + application_name +"/plots.py")
                    os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/LICENSE -L https://raw.githubusercontent.com/weilly0912/ATU_NXP_AI_DEMO/v12.0/TensorflowLite_DEMO/" + application_name +"/LICENSE")
                    os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/" + model_name + " -L https://github.com/weilly0912/ATU_NXP_AI_DEMO/raw/v11.0/TensorflowLite_DEMO/" + application_name + "/model/" + model_name)
                    os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/img/" + test_image_name + " -L https://raw.githubusercontent.com/weilly0912/ATU_NXP_AI_DEMO/v12.0/TensorflowLite_DEMO/" + application_name +"/img/" + test_image_name)
                    if (label_name):
                        os.system("curl -o /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/label/" + label_name + " -L https://raw.githubusercontent.com/weilly0912/ATU_NXP_AI_DEMO/v12.0/TensorflowLite_DEMO/" + application_name +"/label/" + label_name)
                        os.system("sed -i 's|default=\"label/"+ label_name +"\"|default=\"/home/root/.ATU_NXP_AI_DEMO/" + application_name +"/label/" + label_name + "\"|g' " + "/home/root/.ATU_NXP_AI_DEMO/" + application_name + "/app.py")
                else:
                    print("Not connected to the internet")
                    sys.exit()  

            # Compile Model
            if self.hostname=="opgyro" or self.hostname=="imx93evk":
                os.system("vela --output_dir /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/ /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/" + model_name )
                model_name = model_name[:-7] + "_vela.tflite" 

            # Select Delegate
            if self.acceleratorEngine == "npu" or self.acceleratorEngine == "gpu":
                delegate =  ""
            else :
                delegate =  " --delegate xnnpack"

            # Run Model
            if(app_gst==False):
                if (self.args.cam):
                    cam_device = self.args.cam[1]
                    os.system("sed -i \"s|cv2.VideoCapture([^)]*)|cv2.VideoCapture('v4l2src device=/dev/video" + cam_device + " ! video/x-raw,format=YUY2,width=1280,height=720,framerate=30/1! videoscale!videoconvert ! appsink')|g\" " + "/home/root/.ATU_NXP_AI_DEMO/" + application_name + "/app.py" )
                    os.system("python3 /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/app.py" + " -m /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/" + model_name +  " --test_img /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/img/" + test_image_name + " -d 1 -t 1 -c 1 --save 0"  +  delegate)
                else:
                    os.system("python3 /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/app.py" + " -m /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/" + model_name +  " --test_img /home/root/.ATU_NXP_AI_DEMO/" + application_name +"/img/" + test_image_name + " -d 1 -t 1 --save 0" + delegate )
            else:

                if (self.args.cam==0):
                    _cam = "2"
                else:
                    _cam = self.args.cam[1]

                os.system("gst-launch-1.0 --no-position v4l2src device=/dev/video"+  _cam + " ! \
                            video/x-raw,width=640,height=480,framerate=30/1 ! \
                            tee name=t t. ! queue max-size-buffers=2 leaky=2 ! \
                            imxvideoconvert_g2d ! \
                            video/x-raw,width=300,height=300,format=RGBA ! \
                            videoconvert ! video/x-raw,format=RGB ! \
                            tensor_converter ! \
                            tensor_filter framework=tensorflow-lite model=" + "/home/root/.ATU_NXP_AI_DEMO/" + application_name +"/model/" + model_name + " custom=Delegate:External,ExtDelegateLib:libvx_delegate.so ! \
                            tensor_decoder mode=bounding_boxes option1=tf-ssd option2="  + "/home/root/.ATU_NXP_AI_DEMO/" + application_name +"/label/" + label_name +"\
                            option3=0:1:2:3,50 option4=640:480 option5=300:300 ! \
                            mix. t. ! queue max-size-buffers=2 ! \
                            imxcompositor_g2d name=mix sink_0::zorder=2 sink_1::zorder=1 ! fpsdisplaysink ")

    def main(self):
        if self.args.vela_compiler_tool:
            self.vela_compiler_tool(self.args.vela_compiler_tool, self.args.recompile)
        elif self.args.run:
            self.run(self.args.run, self.args.accelerator, True)
        elif self.args.benchmark:
            self.benchmark(self.args.benchmark, self.args.accelerator)
        elif self.args.benchmark_loop_generate_file:
            self.benchmark_loop_generate_file(self.args.benchmark_loop_generate_file, self.args.csv, self.args.csv_status, self.args.delegate)
        elif self.args.bsp_version:
            print(" bsp 版本:", self.bsp_version())
        elif self.args.demo:
            self.demo(self.args.demo)
        elif self.args.refer:
            self.atuml_reference()
        elif self.args.info:
            self.atuml_info()
        else:
            print("Please Input  ' atuml --help ' " )


if __name__ == '__main__':
    ATUML().main()






